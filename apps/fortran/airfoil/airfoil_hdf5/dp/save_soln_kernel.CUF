!
! auto-generated by op2.py on 2013-04-18 15:02
!

MODULE SAVE_SOLN_MODULE
USE OP2_FORTRAN_DECLARATIONS
USE OP2_FORTRAN_RT_SUPPORT
USE ISO_C_BINDING
USE OP2_CONSTANTS
USE CUDAFOR
USE CUDACONFIGURATIONPARAMS


! save_solnvariable declarations

REAL(kind=4) :: loopTimeHostsave_soln
REAL(kind=4) :: loopTimeKernelsave_soln
INTEGER(kind=4) :: numberCalledsave_soln


CONTAINS

attributes (device) &
#include "save_soln.inc"


! CUDA kernel function
attributes (global) SUBROUTINE op_cuda_save_soln( &
  & opDat1Devicesave_soln, &
  & opDat2Devicesave_soln, &
  & setSize)
  
  IMPLICIT NONE
  
! local variables
  real(8), DEVICE, INTENT(IN) :: opDat1Devicesave_soln(*)
  real(8), DEVICE :: opDat2Devicesave_soln(*)
  
  INTEGER(kind=4), VALUE :: setSize
  INTEGER(kind=4) :: i1
  
  
  DO i1 = threadIdx%x - 1 + (blockIdx%x - 1) * blockDim%x, setSize - 1, blockDim%x * gridDim%x
    
! kernel call
    
    CALL save_soln( &
    & opDat1Devicesave_soln(i1 * (4) + 1: i1 * (4) + 4), &
    & opDat2Devicesave_soln(i1 * (4) + 1: i1 * (4) + 4) &
    & )
    
  END DO
  
  
END SUBROUTINE


attributes (host) SUBROUTINE save_soln_host( userSubroutine, set, &
  & opArg1, &
  & opArg2 )
  
  IMPLICIT NONE
  character(len=9), INTENT(IN) :: userSubroutine
  TYPE ( op_set ) , INTENT(IN) :: set
  
  TYPE ( op_arg ) , INTENT(IN) :: opArg1
  TYPE ( op_arg ) , INTENT(IN) :: opArg2

  if (getHybridGPU()) then
    CALL save_soln_host_gpu(userSubroutine, set, &
  & opArg1, &
  & opArg2 )
  else
    CALL save_soln_host_cpu(userSubroutine, set, &
  & opArg1, &
  & opArg2 )
  end if

END SUBROUTINE

attributes (host) SUBROUTINE save_soln_cpu(q,qold)
  IMPLICIT NONE

  REAL(kind=8), DIMENSION(4), INTENT(IN) :: q
  REAL(kind=8), DIMENSION(4) :: qold
  INTEGER(kind=4) :: i

  DO i = 1, 4
    qold(i) = q(i)
  END DO
END SUBROUTINE

SUBROUTINE save_soln_host_cpu( userSubroutine, set, &
  & opArg1, &
  & opArg2 )

  IMPLICIT NONE
  character(kind=c_char,len=*), INTENT(IN) :: userSubroutine
  type ( op_set ) , INTENT(IN) :: set

  type ( op_arg ) , INTENT(IN) :: opArg1
  type ( op_arg ) , INTENT(IN) :: opArg2

  type ( op_arg ) , DIMENSION(2) :: opArgArray
  INTEGER(kind=4) :: numberOfOpDats
  INTEGER(kind=4) :: n_upper
  type ( op_set_core ) , POINTER :: opSetCore

  real(8), POINTER, DIMENSION(:) :: opDat1Local
  INTEGER(kind=4) :: opDat1Cardinality

  real(8), POINTER, DIMENSION(:) :: opDat2Local
  INTEGER(kind=4) :: opDat2Cardinality


  INTEGER(kind=4) :: i1

  numberOfOpDats = 2

  opArgArray(1) = opArg1
  opArgArray(2) = opArg2

  n_upper = op_mpi_halo_exchanges(set%setCPtr,numberOfOpDats,opArgArray)

  opSetCore => set%setPtr

  opDat1Cardinality = opArg1%dim * getSetSizeFromOpArg(opArg1)
  opDat2Cardinality = opArg2%dim * getSetSizeFromOpArg(opArg2)
  CALL c_f_pointer(opArg1%data,opDat1Local,(/opDat1Cardinality/))
  CALL c_f_pointer(opArg2%data,opDat2Local,(/opDat2Cardinality/))


  DO i1 = 0, n_upper-1, 1

! kernel call
  CALL save_soln_cpu( &
    & opDat1Local(1 + i1 * (4) : i1 * (4) + 4), &
    & opDat2Local(1 + i1 * (4) : i1 * (4) + 4) &
    & )
  END DO

  IF ((n_upper .EQ. 0) .OR. (n_upper .EQ. opSetCore%core_size)) THEN
    CALL op_mpi_wait_all(numberOfOpDats,opArgArray)
  END IF


  CALL op_mpi_set_dirtybit(numberOfOpDats,opArgArray)

END SUBROUTINE

attributes (host) SUBROUTINE save_soln_host_gpu( userSubroutine, set, &
  & opArg1, &
  & opArg2 )
  
  IMPLICIT NONE
  character(len=9), INTENT(IN) :: userSubroutine
  TYPE ( op_set ) , INTENT(IN) :: set
  
  TYPE ( op_arg ) , INTENT(IN) :: opArg1
  TYPE ( op_arg ) , INTENT(IN) :: opArg2
  
  TYPE ( op_arg ) , DIMENSION(2) :: opArgArray
  INTEGER(kind=4) :: numberOfOpDats
  INTEGER(kind=4) :: n_upper
  INTEGER(kind=4) :: returnSetKernelTiming
  
  
  real(8), DIMENSION(:), DEVICE, ALLOCATABLE :: opDat1Devicesave_soln
  real(8), DIMENSION(:), DEVICE, ALLOCATABLE :: opDat2Devicesave_soln
  
  INTEGER(kind=4) :: opDat1Cardinality
  INTEGER(kind=4) :: opDat2Cardinality
  
  INTEGER(kind=4) :: blocksPerGrid
  INTEGER(kind=4) :: threadsPerBlock
  INTEGER(kind=4) :: dynamicSharedMemorySize
  INTEGER(kind=4) :: threadSynchRet
  INTEGER(kind=4), SAVE :: calledTimes
  INTEGER(kind=4) :: i1
  INTEGER(kind=4) :: i2
  INTEGER(kind=4) :: i10
  INTEGER(kind=4) :: i20
  
  INTEGER(kind=4) :: istat
  REAL(kind=4) :: accumulatorHostTime
  REAL(kind=4) :: accumulatorKernelTime
  REAL(kind=8) :: KT_double
  TYPE ( cudaEvent )  :: startTimeHost
  TYPE ( cudaEvent )  :: endTimeHost
  TYPE ( cudaEvent )  :: startTimeKernel
  TYPE ( cudaEvent )  :: endTimeKernel
  
  numberOfOpDats = 2
  
  opArgArray(1) = opArg1
  opArgArray(2) = opArg2
  
  n_upper = op_mpi_halo_exchanges_cuda(set%setCPtr,numberOfOpDats,opArgArray)
  
  istat = cudaEventCreate(startTimeHost)
  istat = cudaEventCreate(endTimeHost)
  istat = cudaEventCreate(startTimeKernel)
  istat = cudaEventCreate(endTimeKernel)
  
  numberCalledsave_soln = numberCalledsave_soln + 1
  istat = cudaEventRecord(startTimeHost,0)
  
  
  blocksPerGrid = 200
  threadsPerBlock = getBlockSize(userSubroutine//C_NULL_CHAR,set%setPtr%size)
  dynamicSharedMemorySize = reductionSize(opArgArray,numberOfOpDats) * threadsPerBlock
  
  opDat1Cardinality = opArg1%dim * getSetSizeFromOpArg(opArg1)
  opDat2Cardinality = opArg2%dim * getSetSizeFromOpArg(opArg2)
  
  
  CALL c_f_pointer(opArg1%data_d,opDat1Devicesave_soln,(/opDat1Cardinality/))
  CALL c_f_pointer(opArg2%data_d,opDat2Devicesave_soln,(/opDat2Cardinality/))
  
  istat = cudaEventRecord(endTimeHost,0)
  istat = cudaEventSynchronize(endTimeHost)
  istat = cudaEventElapsedTime(accumulatorHostTime,startTimeHost,endTimeHost)
  
  loopTimeHostsave_soln = loopTimeHostsave_soln + accumulatorHostTime
  istat = cudaEventRecord(startTimeKernel,0)
  
  CALL op_cuda_save_soln <<<blocksPerGrid,threadsPerBlock,dynamicSharedMemorySize>>>( &
  & opDat1Devicesave_soln, &
  & opDat2Devicesave_soln, &
  set%setPtr%size)
  
  IF ((n_upper .EQ. 0) .OR. (n_upper .EQ. set%setPtr%core_size)) THEN
    CALL op_mpi_wait_all_cuda(numberOfOpDats,opArgArray)
  END IF
  
  
  istat = cudaEventRecord(endTimeKernel,0)
  istat = cudaEventSynchronize(endTimeKernel)
  istat = cudaEventElapsedTime(accumulatorKernelTime,startTimeKernel,endTimeKernel)
  loopTimeKernelsave_soln = loopTimeKernelsave_soln + accumulatorKernelTime
  
  
  CALL op_mpi_set_dirtybit_cuda(numberOfOpDats,opArgArray)
  
  KT_double = REAL(accumulatorKernelTime / 1000.00)
  returnSetKernelTiming = setKernelTime(0 , userSubroutine//C_NULL_CHAR, &
  & KT_double, 0.00000,0.00000)
  calledTimes = calledTimes + 1
END SUBROUTINE
END MODULE
